---
title: "Learning to Learn and Beyond"
description: "Module 1, Foundations 2"
 
author:
  - name: Robbie Ball 
    url: https://twitter.com/ElephantNeurons
    affiliation: CUNY Graduate Center
    affiliation_url: https://www.gc.cuny.edu/
date: 09-11-2020
bibliography: Week 2.bib
csl: apa.csl
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Learn more about creating blogs with Distill at:
# https://rstudio.github.io/distill/blog.html

```

# 0
The most fascinating part about our human quest for modeling the mind is taking what is learned one step further and applying it in a new context. Understanding that how we learn is not human-exclusive is, in my opinion, a huge step for Cognitive Psychology. I refer specifically to how we can apply models of learning and memory to Artificial Intelligence. I find this particularly interesting because my interest in psychology is more focused in comparative cognition, where my research experience is practiced in observational and experimental field work with non-human primates. It might seem silly to compare a high-tech Google AI machine to a Chimpanzee, but they both are essentially closest to human in terms of cognition. 

The readings from this week do not really focus on this comparison I am making, but I am drawn to this idea after reading the papers because of how Richard Semon’s theory of memory continues to influence modern applications of learning. In Hintzman’s Schema Abstraction article [@hintzman__1986], he mentions how Semon emphasized sensory features and restricted much of his work to being less human-centric, likely because of his background in Zoology. Hintzman’s MINERVA 2 must have taken inspiration from this idea of focusing on bits of information learned and stored without the context of ‘how would a human do this.’ Instead, the model focuses on the more computationally driven side of memory retrieval, rather than perhaps being biased in a human-centric philosophy. To compare with animals again, humans learn a significant amount of information in their lives through academic, pedagogical education systems. However, pedagogy does not exist in all realms of the animal kingdom. Pedagogy is a result of developed social structures. Many animals learn only through imprinted genetic coding and their own sensory-based observations. This is pretty much how artificial intelligence learns, right? An AI can be hardcoded to ‘know’ something, or it can ‘observe’ data through whatever possible means it has access. We are not at the point where computers go to school to learn from computer teachers, so I truly feel it has been a vital achievement in science to realize that learning and memory existed before we did and still do outside of our species.

# 1
To elaborate more on this in reference to Hintzman, his general question over whether abstractions are separate from episodic memories feels pertinent today in how we design AI to understand information. Are abstract generalizations a separate source of information than empirical memories or are they traces of said empirical memories? I think a great way of understanding this issue is looking at how we define terms. This idea was presented to me by a professor from my undergraduate course in Cognitive Ethnography. How would we tell someone/something what a ‘bachelor’ is, knowing they have no social context for the word? We may define a bachelor as a single male. But is an eight-year-old boy a bachelor? It fits the definition, but contextually, no. A bachelor should be a single male adult. Does that make the Pope a bachelor? Again, contextually no. Is there a perfect operational definition for the word? Maybe, but we do not actively think about the amount of bits needed to be assessed when deciding if someone is a bachelor. We more than likely have ideas and examples of what we consider a bachelor and draw on them when categorizing someone. Hintzman discusses throughout the paper how context specificity matters in categorizing appropriately. What makes sense in one context may not in another, just like the beverage example he discusses. Abstractly, milk seems like less of a beverage choice than milk and tea, but when in the context of doughnuts, milk ascends to a higher tier of appropriateness. [@hintzman__1986] Context specificity seems to be a running theme in the papers from this week, and I cannot agree more that it is a keystone of understanding information theory with a deeper level of design.

# 2
Aujla et al. 2019 makes a wonderful case for this need to design around context specificity. The criticism toward word match in search results resonated heavily with me. I draw on the specific memory of when I was writing a final paper for a class about gibbon cognition and I had collected a dozen or so academic papers to discuss on the history of studies regarding the Lesser Ape. I started to read one of the papers and was confused why the paper discussed a topic I had no clue about. I searched for papers about gibbons, why would something else come up? It turned out the paper was written by John Gibbons. Its still my fault for not realizing sooner, but why would Google Scholar’s top results include a paper unrelated to the other top results outside of a single word match?

Word match struggles because it is a one-dimensional approach to association and so much contextual information is lost in the process. Therefore, the vector-space model of semantics in encoding specificity is the only way to improve. I do not even see it as an alternative approach, but just one of greater dimensions. I had not thought of context as a matrix until this paper, but it makes so much sense. We store so much information as text, but we leave humans to do the job of interpreting context outside of that text. 

Therefore, the answer is to start encoding semantics into the information we record. While the invention of the cognitive search engine is neat enough already, it seems obvious to me that this methodology does not adhere to article searching only. Encoding semantics is something I think would augment our communication abilities. Have you ever read or sent a text and had the context completely missed? We send information all the time that has potential for encoded semantics to be lost. Ideally, the more dimensions of information we can encode in a message, the more accurate our communication is. That might be an oversimplification, but the results from this paper clearly show that BEAGLE’s semantic vector methods found target documents faster than non-semantic or just word-match [@aujla_semantic_2019]. I think it would be reasonable then to assume that an analogous approach to any information recorded or sent would be more efficiently retrieved if there are more dimensions to pinpoint when searching or receiving.

Viewing this computationally cognitive approach to psychology as analogous to biologically inspired engineering, as Aujla et al do, seems like less of an analogy to me and more of the same method. I am starting to view 'our minds as computational' not as a perspective, but as how they were engineered. Evolution paved the way through millions of iterations to create our minds and bodies. We have tools and create tools to solve problems because our biology allows us. In the words of Dr. Ian Malcolm, “Life…finds a way.” We now continue that through our design of machines that model ours and improve, albeit on a much smaller time frame than evolution took.

# 3
The last piece of this amalgam is the practice of practice. Crump et al. 2019 use inter-word keystroke interval (IKSI) response times to infer that Instance Theory predicts Information Theory.Considering the focus on experience-based knowledge through instance theory, I wish there were some detail to the intuition behind the ‘QWERTY’ keyboard design. I spent a little time researching this design, and it turns out that why we use the QWERTY keyboard is somewhat of a mystery. It looks like the design became popularized by Morse code usage, but the exact details are vague at best [@david_clio_1985]. Could there then be a more intuitive design, using knowledge of IKSI data, to lower response times?

Additionally, I would like to see how the data might differ with typing in other languages. I know other Roman alphabet languages use similar but not exact keyboards; would the data differ slightly? What about languages using completely different characters, such as Arabic or Korean? My guess would be the results of the paper would be similar because a different language should not invalidate the claim that prior experience informs a faster and more efficient retrieval[@crump_instance_2018]. However, would first letter slowing be as consistent? Is first letter slowing a result of the grammar system we use? I am very curious to see how this study might evolve and broaden over time.

# 4
Understanding the framework laid by Semon, Miller, Newell, and Hintzman give a clearer sense of connection to how Psychology went from its archaic roots to integrating with computational modeling of system level functions. I doubt Freud saw his patients as mechanisms of multi-dimensional vector-spaces. Perhaps the push toward our understanding of the human mind being one model and not the model of cognition would have been unsettling to early psychologists. Personally, I find this approach exciting and look forward to being a part of continuing work toward a species-neutral view of cognition.



